# -*- coding: utf-8 -*-
"""face_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qhMFaCqnjYS3Jl55bi2Kz6xEnlg95ryr
"""

import csv  # noqa
from os import listdir  # noqa
from os.path import isdir  # noqa

import cv2  # noqa
import matplotlib.pyplot as plt  # noqa
import numpy as np
from constants import IMG_SHAPE  # noqa
from mtcnn.mtcnn import MTCNN  # noqa
from PIL import Image  # noqa
from keras.models import load_model, model_from_json  # noqa
from numpy import asarray, expand_dims, load, savez_compressed  # noqa
import pandas as pd

class FaceDetection:
    def __init__(self):
        pass

    def find_face(self, img: file_path) -> np.asarray:
        image = Image.open(img)
        # convert to RGB, if needed
        image = image.convert("RGB")
        # convert to array
        pixels = asarray(image)
        # create the detector, using default weights
        detector = MTCNN()
        # detect faces in the image
        results = detector.detect_faces(pixels)
        # extract the bounding box from the first face
        save=[]
        
        for i in range(len(results)):          
          x1, y1, width, height = results[i]["box"]
          # bug fix
          x1, y1 = abs(x1), abs(y1)
          x2, y2 = x1 + width, y1 + height
          # extract the face
          face = pixels[y1:y2, x1:x2]
          # resize pixels to the model size
          image = Image.fromarray(face)
          image = image.resize((160,160))
          save.append(asarray(image))
        o_p=np.array(save)
        if o_p.shape[0]==1:
          return np.array(save)[0]
        else:
          return o_p
          
class FaceVerification:
    def __init__(self):
        pass

    def get_embedding(self, model, face_pixels: np.array) -> np.asarray:
        # scale pixel values
        face_pixels = face_pixels.astype("float32")
        # standardize pixel values across channels (global)
        mean, std = face_pixels.mean(), face_pixels.std()
        face_pixels = (face_pixels - mean) / std
        # transform face into one sample
        if face_pixels.shape[0]==160:
          samples = expand_dims(face_pixels, axis=0)
        else:
          samples = face_pixels
        # make prediction to get embedding
        yhat = model.predict(samples)
        return yhat

    def get_facenet_model(FACENET_MODEL_PATH): ->model
        model = load_model(FACENET_MODEL_PATH)
        return model
      
    def get_model(self,MODEL_PATH,WEIGHT_PATH):
        json_file = open(MODEL_PATH, "r")
        loaded_model_json = json_file.read()
        json_file.close()
        loaded_model = model_from_json(loaded_model_json)
        # load weights into new model
        loaded_model.load_weights(WEIGHT_PATH)
        return loaded_model
        
class FaceRecognition:
    def __init__(self):
        pass
    def load_database(self,DATA_PATH): ->np.asarray
        df=pd.read_csv(DATA_PATH)
        name=df['name']
        encodings=[]
        for index,row in df.iterrows():
          enc=[]
          for i in range(1,129):
            enc.append(row[str(i)])
          encodings.append(enc)
        return np.asarray(encodings),name

    def add_in_db(self,person_name,embeddings):
          l=[person_name] 
          for i in range(0,128):
            l.append(embeddings[0][i])
          with open(DATA_PATH) as newFile:
              newFileWriter = csv.writer(newFile)
              newFileWriter.writerow(l)